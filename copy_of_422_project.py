# -*- coding: utf-8 -*-
"""Copy of 422 Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aW2_kqmM6TKHTP7iYId-OTyooA3guolk

## **STEPS:**

Basic Pipeline for solving a ML project:

1. Read in Dataset

2. Get to know your dataset using data vizualisation and other techniques

3. Preprocess your dataset:

  * remove/impute null values
  * remove outliers
  * feature scaling
  * feature engineering
  * feature selection

4. train/test split
5. choose and build (number of) machine learning algorithm
5. train model on training data
6. make prediction on test data
7. evaluate performance on test data
8. visualization of your results
"""



"""https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones"""

from google.colab import drive

drive.mount('/content/drive')

#importing necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

train_dataset = pd.read_csv('/content/drive/MyDrive/Datasets/train.csv')
train_dataset.shape

test_dataset = pd.read_csv('/content/drive/MyDrive/Datasets/test.csv')

"""## **Creating Dataframe**"""

feature_names1 = list(train_dataset.keys())
train_frame = pd.DataFrame(train_dataset, columns=feature_names1)


feature_names2 = list(test_dataset.keys())
test_frame = pd.DataFrame(test_dataset, columns=feature_names2)
main_frame= pd.concat([train_frame, test_frame], ignore_index=True)

"""##**Data Analysis**"""

main_frame.shape

null=train_dataset.isnull().sum().sum()

print(f"Total number of Null values in Dataset: {null}")

ac=main_frame['Activity'].unique()
for i in ac:
  print(i)

non_numeric_columns = main_frame.select_dtypes(exclude='number').columns

# Count the number of non-numeric columns
num_non_numeric_columns = len(non_numeric_columns)

print(f'The number of columns with non-numeric values is: {num_non_numeric_columns}')
print('Non-numeric columns:', non_numeric_columns)

main_frame.head(100)

"""##**Pre-Processing**

Null Values: (As Dataset didn't have any null values to begin with, we are inserting null values for demonstration purposes)
"""

np.random.seed(42)

# Insert 30 random null values (excluding 'Activity' and 'subject' columns)
for _ in range(30):
    random_row_index = np.random.randint(0, len(main_frame))
    random_column = np.random.choice(main_frame.columns[~main_frame.columns.isin(['Activity', 'subject'])])
    main_frame.at[random_row_index, random_column] = np.nan

# Display the number of null values
total_null_values = main_frame.isnull().sum().sum()
print(f"Total number of null values in the dataset: {total_null_values}")

# Replace null values based on the average value for the corresponding 'Activity'
for activity in main_frame['Activity'].unique():
    activity_rows = main_frame[main_frame['Activity'] == activity]
    for column in main_frame.columns[~main_frame.columns.isin(['Activity', 'subject'])]:
        column_avg = activity_rows[column].mean()
        main_frame.loc[activity_rows.index, column] = activity_rows[column].fillna(column_avg)

# Verify that there are no null values after replacement
total_null_values_after_replace = main_frame.isnull().sum().sum()
print(f"Total number of null values in the dataset after replacement: {total_null_values_after_replace}")

"""Categorical Value Encoding:

Since dataset didn't have any categorical values to encode, the subject column has been categorized for demonstration
"""

main_frame['subject'] = 'subject_' + main_frame['subject'].astype(str)
main_frame['subject'].unique()

"""Categorical Value, Solution 1: Encoding"""

main_frame['subject'] = main_frame['subject'].str.extract('(\d+)').astype(int)
main_frame['subject'].unique()

"""Categorical Value, Solution 1: Dropping the column"""

main_frame.drop('subject', axis=1, inplace=True)

"""##**Feature Scaling:**
Was not required

##**Seperating Trainning Data and Test Data**
"""

from sklearn.model_selection import train_test_split

X = main_frame.drop('Activity', axis=1)
Y = main_frame['Activity']



# 70/30 split for training and testing data
train_set, test_set = train_test_split(main_frame, test_size=0.3, random_state=42,stratify=Y)


X_train = train_set.drop('Activity', axis=1)
Y_train = train_set['Activity']


X_test = test_set.drop('Activity', axis=1)
Y_test = test_set['Activity']

"""##**Data Visualization**

Correlation Heatmap of the entire Dataset:
"""

target_feature = 'Activity'


selected_columns = main_frame.columns[main_frame.columns != target_feature]


sampled_data = main_frame.groupby(target_feature, group_keys=False).apply(lambda x: x.sample(min(len(x), 50)))


correlation_matrix = sampled_data[selected_columns].corr(numeric_only=True)

plt.figure(figsize=(15, 12))


sns.heatmap(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1, annot=False)


plt.show()

"""Correlation heatmap of 20 random features to understand the relations:"""

import random

target_feature = 'Activity'

selected_columns = main_frame.columns[main_frame.columns != target_feature]


random_columns = random.sample(selected_columns.tolist(), 20)

sampled_data = main_frame.groupby(target_feature, group_keys=False).apply(lambda x: x.sample(min(len(x), 50)))


correlation_matrix = sampled_data[random_columns].corr(numeric_only=True)

plt.figure(figsize=(15, 12))

sns.heatmap(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1, annot=False)

plt.show()

"""Data Distribution of Trainning Set:"""

plt.figure(figsize=(35, 6))
plt.subplot(1, 2, 1)
sns.countplot(x='Activity', data=train_set)
plt.title('Training Set - Activity Distribution')
plt.show()

"""Data Distribution of Test Set:"""

plt.figure(figsize=(35, 6))
plt.subplot(1, 2, 2)
sns.countplot(x='Activity', data=test_set)
plt.title('Testing Set - Activity Distribution')
plt.show()

"""## **Trainning and Prediction Accuracy:**

##**Model 1: Decision Tree (RandomForestClassifier)**
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


model = RandomForestClassifier(n_estimators=500, random_state=42)
model.fit(X_train, Y_train)



Y_pred = model.predict(X_test)


accuracy = accuracy_score(Y_test, Y_pred)
print(f'Accuracy: {accuracy:.2f}')


print(classification_report(Y_test, Y_pred))

"""Visualization:"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)

plt.figure(figsize=(20, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix For RandomForrestClassifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)

# Create a bar chart
plt.figure(figsize=(18, 6))
sns.barplot(x=model.classes_, y=class_accuracy, color='skyblue')
plt.title('Prediction Accuracy for Each Class')
plt.xlabel('Activity')
plt.ylabel('Accuracy')
plt.ylim(0, 1)  # Set y-axis limits to represent accuracy percentage
plt.show()

"""##**Model 2: K-Nearest Neighbors (KNeighborsClassifier)**"""

from sklearn.neighbors import KNeighborsClassifier


knn_model = KNeighborsClassifier(n_neighbors=5)


knn_model.fit(X_train, Y_train)


Y_pred_knn = knn_model.predict(X_test)


accuracy_knn = accuracy_score(Y_test, Y_pred_knn)
print(f'K-Nearest Neighbors Accuracy: {accuracy_knn:.2f}')


print('Classification Report for K-Nearest Neighbors:')
print(classification_report(Y_test, Y_pred_knn))

"""Visualization:"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred_knn)


plt.figure(figsize=(20, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix For KNeighborsClassifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy_knn = conf_matrix.diagonal() / conf_matrix.sum(axis=1)

# Create a bar chart
plt.figure(figsize=(18, 6))
sns.barplot(x=knn_model.classes_, y=class_accuracy_knn, color='lightcoral')
plt.title('K-Nearest Neighbors - Prediction Accuracy for Each Class')
plt.xlabel('Activity')
plt.ylabel('Accuracy')
plt.ylim(0, 1)  # Set y-axis limits to represent accuracy percentage
plt.show()

"""##**Support Vector Machine (SVM)**"""

from sklearn.svm import SVC


svm_model = SVC(kernel='linear', C=1.0)


svm_model.fit(X_train, Y_train)

Y_pred_svm = svm_model.predict(X_test)


accuracy_svm = accuracy_score(Y_test, Y_pred_svm)
print(f'Support Vector Machine Accuracy: {accuracy_svm:.2f}')


print('Classification Report for Support Vector Machine:')
print(classification_report(Y_test, Y_pred_svm))

"""Visualization:"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred_svm)

plt.figure(figsize=(18, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix FOR SVM')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy_knn = conf_matrix.diagonal() / conf_matrix.sum(axis=1)

# Create a bar chart
plt.figure(figsize=(18, 6))
sns.barplot(x=knn_model.classes_, y=class_accuracy_knn, color='lightgreen')
plt.title('Support Vector Machine - Prediction Accuracy for Each Class')
plt.xlabel('Activity')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()